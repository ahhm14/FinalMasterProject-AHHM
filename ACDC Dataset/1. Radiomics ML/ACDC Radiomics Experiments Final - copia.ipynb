{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACDC Challenge \n",
    "\n",
    "In this notebook we will try to obatain the best model for classiying CVD with the use of radiomics data.\n",
    "\n",
    "We will create a pipeline to work through the data and compare the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the packages and libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFECV, RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "# from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline\n",
    "\n",
    "1. Dataset \n",
    "2. Feature Engineering/Selection\n",
    "4. ML Algorithms\n",
    "5. Training and Testing on ACDC Challenge Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset\n",
    "\n",
    "We will load the training and test dataset, which contain the extracted radiomics of 100 and 50 patients, respectively. It will also contain the clinical data (only height and weight available) and the class of the patient (each of the 4 diseases or normal state). We will create a function to prepare the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 777)\n",
      "(50, 777)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('Extracted_radiomics\\ACDC_(Radiomics+Clinical)_Training.csv')\n",
    "print(train_df.shape)\n",
    "test_df = pd.read_csv('Extracted_radiomics\\ACDC_(Radiomics+Clinical)_Testing.csv')\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from prior knowledge that both the train and test dataset are equally balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know that there are features that are not numeric and are just the product of the of the radiomics library that will not be needed for our model. We show them and we are going to eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 645)\n",
      "(50, 645)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[:,~ train_df.columns.str.startswith('diagnostics')]\n",
    "test_df = test_df.loc[:,~ test_df.columns.str.startswith('diagnostics')]\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['class']\n",
    "y_test = test_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ED_train_df = train_df.filter(regex='ED')\n",
    "ES_train_df = train_df.filter(regex='ES')\n",
    "\n",
    "ED_test_df = test_df.filter(regex='ED')\n",
    "ES_test_df = test_df.filter(regex='ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED_train_df = pd.concat([ED_train_df, class_df_train], axis=1)\n",
    "# ES_train_df = pd.concat([ES_train_df, class_df_train], axis=1)\n",
    "\n",
    "# ED_test_df = pd.concat([ED_test_df, class_df_test], axis=1)\n",
    "# ES_test_df = pd.concat([ES_test_df, class_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_train = pd.concat([ED_train_df, ES_train_df], axis = 1)\n",
    "rad_test = pd.concat([ED_test_df, ES_test_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_info_train = train_df.iloc[:,-3:-1]\n",
    "med_info_test = test_df.iloc[:,-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_train = pd.concat([rad_train, med_info_train], axis=1)\n",
    "all_data_test = pd.concat([rad_test, med_info_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 642)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering\n",
    "* MinMaxScaler for all the features \n",
    "* Encoding Class values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(X_train,y_train, X_test, y_test):\n",
    "    #tools scaling and labelling\n",
    "    scaler = MinMaxScaler()\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection\n",
    "\n",
    "For this section we aim to apply several techiniques for feature selection and compare the performance with each proposed model/learning algorithm of the section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set of Techniques we are going to use:\n",
    "1. <u> K-Best </u>: This method is a **filter method**, which select features according the K-Highest Score of an statistical Test. For this one we are going to use both **Anova-Test** and **Chi-Suared-Test**.\n",
    "\n",
    "2. <u> Sequential Forward Feature Elimination </u>: automatically select a subset of features that is most relevant to the problem. The goal of feature selection is two-fold: We want to improve the computational efficiency and reduce the generalization error of the model by removing irrelevant features or noise. http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/#example-1-a-simple-sequential-forward-selection-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine Feature Selection methods as part of the Grid Search Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBest_GS(X_train, y_train, X_test, y_test, model, param_grid, df):\n",
    "    \n",
    "    featss =np.arange(3,X_train.shape[1])\n",
    "    \n",
    "    selector = SelectKBest()\n",
    "    \n",
    "    ### Pipeline\n",
    "    \n",
    "    ### we would need to adapt the \"NUMBER OF FEATURES PARAMETER OF THE GRID\"\n",
    "    \n",
    "    pipe = Pipeline([('selector', selector), \n",
    "                 ('model', model)])\n",
    "    \n",
    "    dict_1 = {'selector__score_func': [f_classif, chi2],\n",
    "              'selector__k':featss}   #### para pruebas\n",
    "    \n",
    "    dict_1.update(param_grid)\n",
    "    \n",
    "    gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=dict_1, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=StratifiedKFold(4, shuffle=True, random_state=42),\n",
    "                  iid=True,\n",
    "                  refit=True,\n",
    "                verbose=1)\n",
    "    \n",
    "    print(pipe.get_params().keys())\n",
    "    \n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Model\", gs.best_params_)\n",
    "    \n",
    "    print('Best score:', gs.best_score_)\n",
    "    \n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    \n",
    "    test_acc = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    print(\"\\n Test Accuracy with best estimator: \", test_acc)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm)\n",
    "        \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    \n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    class_list = ['DCM', 'HCM', 'MINF', 'NOR', 'RV']\n",
    "\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks+0.5, class_list, rotation=45)\n",
    "    plt.yticks(tick_marks+0.5, class_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred,target_names=class_list))\n",
    "    \n",
    "    cols = gs.best_estimator_.steps[0][1].get_support(indices=True)\n",
    "    print(df.iloc[:,cols].columns)\n",
    "    K_best= df.iloc[:,cols].columns\n",
    "    \n",
    "    \n",
    "    return gs, K_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Sequential Foward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Grid Search Sequential Forward Elimination\n",
    "\n",
    "def SFS_GS(X_train, y_train, X_test, y_test, model, param_grid, df):\n",
    "    # Setting up the SFS\n",
    "    sfs1 = SFS(estimator=model,\n",
    "               k_features=15,\n",
    "               forward=True,\n",
    "               floating=False,\n",
    "               scoring='accuracy',\n",
    "               cv=StratifiedKFold(3, shuffle=True, random_state=42))\n",
    "\n",
    "    ### Pipeline\n",
    "\n",
    "    ### we would need to adapt the \"NUMBER OF FEATURES PARAMETER OF THE GRID\"\n",
    "\n",
    "    pipe = Pipeline([('sfs', sfs1),\n",
    "                     ('model', model)])\n",
    "\n",
    "    # dict_1 = {'sfs__k_features':list(range(1,X_train.shape[1]))}   #### para pruebas\n",
    "\n",
    "    dict_1 = {'sfs__k_features': [5,10]}  # pruebas\n",
    "\n",
    "    dict_1.update(param_grid)\n",
    "\n",
    "    gs = GridSearchCV(estimator=pipe,\n",
    "                      param_grid=dict_1,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      cv=StratifiedKFold(4, shuffle=True, random_state=42),\n",
    "                      verbose=3,\n",
    "                      refit=True)\n",
    "\n",
    "    #     print(pipe.get_params().keys())\n",
    "\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "\n",
    "    #     print(gs.best_estimator_.steps)\n",
    "\n",
    "    print(\"Best Model\", gs.best_params_)\n",
    "\n",
    "    #     print('Best score:', gs.best_score_)\n",
    "\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"\\n Test Accuracy with best estimator: \", test_acc)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    class_list = ['DCM', 'HCM', 'MINF', 'NOR', 'RV']\n",
    "\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks+0.5, class_list, rotation=45)\n",
    "    plt.yticks(tick_marks+0.5, class_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred, target_names=class_list))\n",
    "\n",
    "    feats = gs.best_estimator_.steps[0][1].k_feature_idx_\n",
    "\n",
    "    feats_2 = np.asanyarray(feats)\n",
    "\n",
    "    print(df.iloc[:, feats_2].columns)\n",
    "    feats_names = df.iloc[:, feats_2].columns\n",
    "\n",
    "    return gs, pipe, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ED Alone\n",
    "X_train_ED, y_train, X_test_ED, y_test = processing(ED_train_df, y_train, ED_test_df, y_test)\n",
    "\n",
    "#ES Alone\n",
    "\n",
    "X_train_ES, y_train, X_test_ES, y_test = processing(ES_train_df, y_train, ES_test_df, y_test)\n",
    "\n",
    "#Radiomics \n",
    "\n",
    "X_train_rad, y_train, X_test_rad, y_test = processing(rad_train, y_train, rad_test, y_test)\n",
    "\n",
    "#All data\n",
    "\n",
    "X_train_all, y_train, X_test_all, y_test = processing(all_data_train, y_train, all_data_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ML Algorithms\n",
    "\n",
    "Let's test some algorithms with the feature selection techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classifier\n",
    "\n",
    "model_SVC = SVC(gamma = 'scale', max_iter= 5000, random_state=42)\n",
    "\n",
    "param_grid_SVC =  {'model__kernel':('linear', 'rbf'), \n",
    "                   'model__C':[0.5, 1, 10]}\n",
    "\n",
    "# param_grid_SVC_nested =  { 'sfs__estimator__kernel': ['linear', 'rbf', 'poly']},\n",
    "#                           {'degree':[1,5,10]},{\n",
    "#                    'sfs__estimator__C':[5]}\n",
    "\n",
    "param_grid_SVC_nested_2 =  { 'selector__estimator__kernel': ['linear', 'rbf'],\n",
    "                   'selector__estimator__C':[15]}\n",
    "\n",
    "param_grid_SVC_test_2 =  { \n",
    "                   'estimator__model__C':[0.5, 1,5,10]}\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "#Random Forest \n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 100,1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4,6,8,10]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "param_grid_RF = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "param_grid_RF_nested = {'model__n_estimators': n_estimators,\n",
    "               'model__max_features': max_features,\n",
    "               'model__max_depth': max_depth,\n",
    "               'model__min_samples_split': min_samples_split,\n",
    "               'model__min_samples_leaf': min_samples_leaf,\n",
    "               'model__bootstrap': bootstrap}\n",
    "\n",
    "param_grid_RF_2 = {'estimator__n_estimators': n_estimators,\n",
    "               'estimator__bootstrap': bootstrap}\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "param_grid_LR_nested = {'model__penalty': ['l1','l2'], \n",
    "               'model__C': [0.1,1,10,100, 200]}\n",
    "\n",
    "param_grid_LR = {'penalty': ['l1','l2'], \n",
    "               'C': [0.1,1,10,100, 200]}\n",
    "\n",
    "model_LR = LogisticRegression( multi_class='auto', random_state=42)\n",
    "\n",
    "#-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training and Testing on ACDC Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['memory', 'steps', 'verbose', 'selector', 'model', 'selector__k', 'selector__score_func', 'model__C', 'model__break_ties', 'model__cache_size', 'model__class_weight', 'model__coef0', 'model__decision_function_shape', 'model__degree', 'model__gamma', 'model__kernel', 'model__max_iter', 'model__probability', 'model__random_state', 'model__shrinking', 'model__tol', 'model__verbose'])\n",
      "Fitting 4 folds for each of 7668 candidates, totalling 30672 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model {'model__C': 10, 'model__kernel': 'linear', 'selector__k': 88, 'selector__score_func': <function f_classif at 0x00000153FE877D38>}\n",
      "Best score: 0.9\n",
      "\n",
      " Test Accuracy with best estimator:  0.88\n",
      "[[ 8  0  2  0  0]\n",
      " [ 0  9  0  1  0]\n",
      " [ 1  0  9  0  0]\n",
      " [ 0  1  0  8  1]\n",
      " [ 0  0  0  0 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 30672 out of 30672 | elapsed:  3.9min finished\n",
      "C:\\Users\\alex1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-c6f48879c449>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKBest_GS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_rad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_rad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_SVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_SVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrad_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-06fbcb456692>\u001b[0m in \u001b[0;36mKBest_GS\u001b[1;34m(X_train, y_train, X_test, y_test, model, param_grid, df)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs, K_best = KBest_GS(X_train_rad, y_train, X_test_rad, y_test, model_SVC, param_grid_SVC, rad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
