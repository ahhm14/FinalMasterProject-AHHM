{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion of Features\n",
    "\n",
    "In this notebook we will develop the pipeline for the fusion of extracted radiomics and deeply learnt features using the ACDC dataset. \n",
    "\n",
    "We will retake the pipeline used for the Radiomics supervised learning section of the project, but now we will add the deeply learnt features preprocessing and combination with radiomics. \n",
    "\n",
    "We will study predictive performance, feature selection and accuracy metrics either indidividually and combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the packages and libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFECV, RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 777)\n",
      "(50, 777)\n"
     ]
    }
   ],
   "source": [
    "###Radiomics\n",
    "\n",
    "RF_df_train = pd.read_csv(r'C:\\Users\\alex1\\Desktop\\ACDC\\Extracted_radiomics\\ACDC_(Radiomics+Clinical)_Training.csv')\n",
    "print(RF_df_train.shape)\n",
    "RF_df_test = pd.read_csv(r'C:\\Users\\alex1\\Desktop\\ACDC\\Extracted_radiomics\\ACDC_(Radiomics+Clinical)_Testing.csv')\n",
    "print(RF_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 645)\n",
      "(50, 645)\n"
     ]
    }
   ],
   "source": [
    "RF_df_train = RF_df_train.loc[:,~ RF_df_train.columns.str.startswith('diagnostics')]\n",
    "RF_df_test = RF_df_test.loc[:,~ RF_df_test.columns.str.startswith('diagnostics')]\n",
    "print(RF_df_train.shape)\n",
    "print(RF_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we separate the medical inputs and separate the independent variable (disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_train = RF_df_train.iloc[:,:-3]\n",
    "med_info_train = RF_df_train.iloc[:,-3:-1]\n",
    "y_train = RF_df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_test = RF_df_test.iloc[:,:-3]\n",
    "med_info_test = RF_df_test.iloc[:,-3:-1]\n",
    "y_test = RF_df_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeply Learned Features\n",
    "\n",
    "We load the Feeply Learned Features from their respective model to later be concatenated with the Radiomics and Medical Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inception\n",
    "\n",
    "path = '/home/alejandro/Documentos/files_master/ACDC_Fusion/Ask_fus/Short Format'\n",
    "\n",
    "incep_DF_train_ED = pd.read_csv(path+'/DLR_IncepModel_train_ED_2.csv', header=None)\n",
    "incep_DF_train_ES = pd.read_csv(path+'/DLR_IncepModel_train_ES_2.csv', header=None)\n",
    "incep_DF_test_ED = pd.read_csv(path+'/DLR_IncepModel_test_ED_2.csv', header=None)\n",
    "incep_DF_test_ES = pd.read_csv(path+'/DLR_IncepModel_test_ES_2.csv', header=None)\n",
    "\n",
    "\n",
    "# AlexNet_DF_train_ED = pd.read_csv(path+'/DLR_AlexNet_train_ED_2.csv', header=None)\n",
    "# AlexNet_DF_train_ES = pd.read_csv(path+'/DLR_AlexNet_train_ES_2.csv', header=None)\n",
    "# AlexNet_DF_test_ED = pd.read_csv(path+'/DLR_AlexNet_test_ED_2.csv', header=None)\n",
    "# AlexNet_DF_test_ES = pd.read_csv(path+'/DLR_AlexNet_test_ES_2.csv', header=None)\n",
    "\n",
    "path2 = '/home/alejandro/Documentos/files_master/ACDC_Fusion/Ask_fus'\n",
    "\n",
    "# AlexNet_DF_train_ED = pd.read_csv(path2+'/DLR_AlexNet_train_ED_3.csv', header=None)\n",
    "# AlexNet_DF_train_ES = pd.read_csv(path2+'/DLR_AlexNet_train_ES_3.csv', header=None)\n",
    "# AlexNet_DF_test_ED = pd.read_csv(path2+'/DLR_AlexNet_test_ED_3.csv', header=None)\n",
    "# AlexNet_DF_test_ES = pd.read_csv(path2+'/DLR_AlexNet_test_ES_3.csv', header=None)\n",
    "\n",
    "#Late Merging Model\n",
    "LM_DF_train_ES = pd.read_csv(path+'/DLR_LM_features_train_ES_2.csv', header=None)\n",
    "LM_DF_train_ED = pd.read_csv(path+'/DLR_LM_features_train_ED_2.csv', header=None)\n",
    "LM_DF_test_ES = pd.read_csv(path+'/DLR_LM_features_test_ES_2.csv', header=None)\n",
    "LM_DF_test_ED = pd.read_csv(path+'/DLR_LM_features_test_ED_2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_DF_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_LM_train=np.asanyarray(LM_DF_train)\n",
    "np_LM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_LM_train():\n",
    "    ED_list = list()\n",
    "    ES_list = list()\n",
    "    \n",
    "    for i in np.arange(1,600,3):\n",
    "        if (i % 2) == 0:\n",
    "            ES_list.append(np_LM_train[i,:])\n",
    "        else:\n",
    "            ED_list.append(np_LM_train[i,:])\n",
    "         \n",
    "    ES = np.asanyarray(ES_list)\n",
    "    ED = np.asanyarray(ED_list)\n",
    "\n",
    "    return ES, ED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES, ED = divide_LM_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train_ES = pd.DataFrame(ES)\n",
    "LM_train_ED = pd.DataFrame(ED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_DF_test_ES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_names(df, cycle):\n",
    "    '''Function to add names to the deeply learned features\n",
    "    to later be identified'''\n",
    "    col_names= ['{}_dlf_{}'.format(cycle, x) for x in range(len(df.columns))]\n",
    "    df.columns = col_names\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creation of datasets\n",
    "incep_DF_train_ED = col_names(incep_DF_train_ED, cycle='ED')\n",
    "incep_DF_train_ES = col_names(incep_DF_train_ES, cycle='ES')\n",
    "\n",
    "incep_DF_train = pd.concat([incep_DF_train_ED, incep_DF_train_ES], axis= 1)\n",
    "incep_train_tot = pd.concat([incep_DF_train, med_info_train], axis=1)\n",
    "\n",
    "incep_DF_test_ED = col_names(incep_DF_test_ED , cycle='ED')\n",
    "incep_DF_test_ES = col_names(incep_DF_test_ES, cycle='ES')\n",
    "\n",
    "incep_DF_test = pd.concat([incep_DF_test_ED, incep_DF_test_ES], axis= 1)\n",
    "incep_test_tot = pd.concat([incep_DF_test, med_info_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet_DF_train_ED = col_names(AlexNet_DF_train_ED, cycle='ED')\n",
    "AlexNet_DF_train_ES = col_names(AlexNet_DF_train_ES, cycle= 'ES')\n",
    "\n",
    "AlexNet_DF_train = pd.concat([AlexNet_DF_train_ED, AlexNet_DF_train_ES], axis= 1)\n",
    "AlexNet_train_tot = pd.concat([AlexNet_DF_train, med_info_train], axis = 1)\n",
    "\n",
    "AlexNet_DF_test_ED = col_names(AlexNet_DF_test_ED, cycle='ED')\n",
    "AlexNet_DF_test_ES = col_names(AlexNet_DF_test_ES, cycle='ES')\n",
    "\n",
    "AlexNet_DF_test = pd.concat([AlexNet_DF_test_ED, AlexNet_DF_test_ES], axis= 1)\n",
    "AlexNet_test_tot = pd.concat([AlexNet_DF_test, med_info_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNetdil_DF_train_ED = col_names(AlexNetdil_DF_train_ED, cycle='ED')\n",
    "AlexNetdil_DF_train_ES = col_names(AlexNetdil_DF_train_ES, cycle= 'ES')\n",
    "\n",
    "AlexNetdil_DF_train = pd.concat([AlexNetdil_DF_train_ED, AlexNetdil_DF_train_ES], axis= 1)\n",
    "AlexNetdil_DF_train_tot = pd.concat([AlexNet_DF_train, med_info_train], axis= 1)\n",
    "\n",
    "AlexNetdil_DF_test_ED = col_names(AlexNetdil_DF_test_ED, cycle='ED')\n",
    "AlexNetdil_DF_test_ES = col_names(AlexNetdil_DF_test_ES, cycle='ES')\n",
    "\n",
    "AlexNetdil_DF_test = pd.concat([AlexNetdil_DF_test_ED, AlexNetdil_DF_test_ES], axis= 1)\n",
    "AlexNetdil_DF_test_tot = pd.concat([AlexNet_DF_test, med_info_test], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_train_ED = col_names(LM_train_ED, cycle='ED')\n",
    "LM_train_ES = col_names(LM_train_ES, cycle='ES')\n",
    "\n",
    "LM_train = pd.concat([LM_train_ED, LM_train_ES], axis=1)\n",
    "LM_train_tot = pd.concat([LM_train, med_info_train], axis=1)\n",
    "\n",
    "LM_DF_test_ED = col_names(LM_DF_test_ED, cycle='ED')\n",
    "LM_DF_test_ES = col_names(LM_DF_test_ES, cycle='ES')\n",
    "\n",
    "LM_test = pd.concat([LM_DF_test_ED, LM_DF_test_ES], axis=1)\n",
    "LM_test_tot = pd.concat([LM_test, med_info_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_DF_train = col_names(VGG_DF_train)\n",
    "VGG_DF_test = col_names(VGG_DF_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fusion of Features and data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we combine both data modalities in a single data frame. Also, we will be performing the necessary scale for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testing_model:\n",
    "    def __init__(self, data1, data2, data3, data4):\n",
    "        self.train1 = data1\n",
    "        self.train2 = data2\n",
    "        self.test1 = data3\n",
    "        self.test2 = data4\n",
    "        \n",
    "    def concatenate(self):\n",
    "        X_train = pd.concat([self.train1, self.train2], axis=1)\n",
    "        X_test = pd.concat([self.test1, self.test2], axis = 1)\n",
    "        \n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(X_train,y_train, X_test, y_test):\n",
    "    #tools scaling and labelling\n",
    "    scaler = MinMaxScaler()\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prueba 1 = Radiomics + ED\n",
    "- prueba 2 = Radiomics + ES\n",
    "- prueba 3 = Radiomics + ES + ED\n",
    "- prubea 4 = Radiomics + ES + ED + Med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search K-Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBest_GS(X_train, y_train, X_test, y_test, model, param_grid, df):\n",
    "    \n",
    "    featss =np.arange(3,X_train.shape[1])\n",
    "    \n",
    "    selector = SelectKBest()\n",
    "    \n",
    "    ### Pipeline\n",
    "    \n",
    "    ### we would need to adapt the \"NUMBER OF FEATURES PARAMETER OF THE GRID\"\n",
    "    \n",
    "    pipe = Pipeline([('selector', selector), \n",
    "                 ('model', model)])\n",
    "    \n",
    "    dict_1 = {'selector__score_func': [f_classif, chi2],\n",
    "              'selector__k':featss}   #### para pruebas\n",
    "    \n",
    "    dict_1.update(param_grid)\n",
    "    \n",
    "    gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=dict_1, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=StratifiedKFold(4, shuffle=True, random_state=42),\n",
    "                  iid=True,\n",
    "                  refit=True,\n",
    "                verbose=3)\n",
    "    \n",
    "    print(pipe.get_params().keys())\n",
    "    \n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Model\", gs.best_params_)\n",
    "    \n",
    "    print('Best score:', gs.best_score_)\n",
    "    \n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    \n",
    "    test_acc = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    print(\"\\n Test Accuracy with best estimator: \", test_acc)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm)\n",
    "        \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    \n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    class_list = ['DCM', 'HCM', 'MINF', 'NOR', 'RV']\n",
    "\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks+0.5, class_list, rotation=45)\n",
    "    plt.yticks(tick_marks+0.5, class_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred,target_names=class_list))\n",
    "    \n",
    "    cols = gs.best_estimator_.steps[0][1].get_support(indices=True)\n",
    "    print(df.iloc[:,cols].columns)\n",
    "    K_best= df.iloc[:,cols].columns\n",
    "    \n",
    "    \n",
    "    return gs, K_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Grid Search Sequential Forward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Grid Search Sequential Forward Elimination\n",
    "\n",
    "def SFS_GS(X_train, y_train, X_test, y_test, model, param_grid, df):\n",
    "    # Setting up the SFS\n",
    "    sfs1 = SFS(estimator=model,\n",
    "               k_features=15,\n",
    "               forward=True,\n",
    "               floating=False,\n",
    "               scoring='accuracy',\n",
    "               cv=StratifiedKFold(3, shuffle=True, random_state=42))\n",
    "\n",
    "    ### Pipeline\n",
    "\n",
    "    ### we would need to adapt the \"NUMBER OF FEATURES PARAMETER OF THE GRID\"\n",
    "\n",
    "    pipe = Pipeline([('sfs', sfs1),\n",
    "                     ('model', model)])\n",
    "\n",
    "    # dict_1 = {'sfs__k_features':list(range(1,X_train.shape[1]))}   #### para pruebas\n",
    "\n",
    "    dict_1 = {'sfs__k_features': [5,10]}  # pruebas\n",
    "\n",
    "    dict_1.update(param_grid)\n",
    "\n",
    "    gs = GridSearchCV(estimator=pipe,\n",
    "                      param_grid=dict_1,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      cv=StratifiedKFold(4, shuffle=True, random_state=42),\n",
    "                      verbose=3,\n",
    "                      refit=True)\n",
    "\n",
    "    #     print(pipe.get_params().keys())\n",
    "\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "\n",
    "    #     print(gs.best_estimator_.steps)\n",
    "\n",
    "    print(\"Best Model\", gs.best_params_)\n",
    "\n",
    "    #     print('Best score:', gs.best_score_)\n",
    "\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"\\n Test Accuracy with best estimator: \", test_acc)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    class_list = ['DCM', 'HCM', 'MINF', 'NOR', 'RV']\n",
    "\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks+0.5, class_list, rotation=45)\n",
    "    plt.yticks(tick_marks+0.5, class_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred, target_names=class_list))\n",
    "\n",
    "    feats = gs.best_estimator_.steps[0][1].k_feature_idx_\n",
    "\n",
    "    feats_2 = np.asanyarray(feats)\n",
    "\n",
    "    print(df.iloc[:, feats_2].columns)\n",
    "    feats_names = df.iloc[:, feats_2].columns\n",
    "\n",
    "    return gs, pipe, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classifier\n",
    "\n",
    "model_SVC = SVC(gamma = 'scale', max_iter= 5000, random_state=42)\n",
    "\n",
    "param_grid_SVC =  {'model__C':[5, 10],\n",
    "                   'model__kernel':('linear', 'rbf')\n",
    "                   }\n",
    "\n",
    "param_grid_SVC_nested_2 =  { 'selector__estimator__kernel': ['linear', 'rbf'],\n",
    "                   'selector__estimator__C':[15]}\n",
    "\n",
    "param_grid_SVC_test_2 =  { \n",
    "                   'estimator__model__C':[0.5, 1,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = processing(X_train_df, y_train)\n",
    "X_test, y_test = processing(X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2690)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Using the features extracted from the Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = testing_model(radiomics_train, incep_DF_train_ED, radiomics_test, incep_DF_test_ED).concatenate()\n",
    "X_train2, X_test2 = testing_model(radiomics_train, incep_DF_train_ES, radiomics_test, incep_DF_test_ES).concatenate()\n",
    "X_train3, X_test3 = testing_model(radiomics_train, incep_DF_train, radiomics_test, incep_DF_test).concatenate()\n",
    "X_train4, X_test4 = testing_model(radiomics_train, incep_train_tot, radiomics_test, incep_test_tot).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, y_train = processing(X_train1, y_train)\n",
    "X_test_1, y_test = processing(X_test1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, y_train = processing(X_train2, y_train)\n",
    "X_test_2, y_test = processing(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, y_train = processing(X_train3, y_train)\n",
    "X_test_3, y_test = processing(X_test3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, y_train = processing(X_train4, y_train)\n",
    "X_test_4, y_test = processing(X_test4, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Using the features extracted from the AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = testing_model(radiomics_train, AlexNet_DF_train_ED, radiomics_test, AlexNet_DF_test_ED).concatenate()\n",
    "X_train2, X_test2 = testing_model(radiomics_train, AlexNet_DF_train_ES, radiomics_test, AlexNet_DF_test_ES).concatenate()\n",
    "X_train3, X_test3 = testing_model(radiomics_train, AlexNet_DF_train, radiomics_test, AlexNet_DF_test).concatenate()\n",
    "X_train4, X_test4 = testing_model(radiomics_train, AlexNet_train_tot, radiomics_test, AlexNet_test_tot).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, y_train, X_test_1, y_test = processing(X_train1, y_train, X_test1, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, y_train, X_test_2, y_test = processing(X_train2, y_train, X_test2, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, y_train = processing(X_train3, y_train)\n",
    "X_test_3, y_test = processing(X_test3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, y_train = processing(X_train4, y_train)\n",
    "X_test_4, y_test = processing(X_test4, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 647)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Using the features extracted from the AlexNetDil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = testing_model(radiomics_train, AlexNetdil_DF_train_ED, radiomics_test, AlexNetdil_DF_test_ED).concatenate()\n",
    "X_train2, X_test2 = testing_model(radiomics_train, AlexNetdil_DF_train_ES, radiomics_test, AlexNetdil_DF_test_ES).concatenate()\n",
    "X_train3, X_test3 = testing_model(radiomics_train, AlexNetdil_DF_train, radiomics_test, AlexNetdil_DF_test).concatenate()\n",
    "X_train4, X_test4 = testing_model(radiomics_train, AlexNetdil_DF_train_tot, radiomics_test, AlexNetdil_DF_test_tot).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, y_train, X_test_1, y_test = processing(X_train1, y_train, X_test1, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, y_train, X_test_2, y_test = processing(X_train2, y_train, X_test2, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, y_train = processing(X_train3, y_train)\n",
    "X_test_3, y_test = processing(X_test3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, y_train = processing(X_train4, y_train)\n",
    "X_test_4, y_test = processing(X_test4, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Using the features extracted from the Late Merging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = testing_model(radiomics_train, LM_train_ED, radiomics_test, LM_DF_test_ED).concatenate()\n",
    "X_train2, X_test2 = testing_model(radiomics_train, LM_train_ES, radiomics_test, LM_DF_test_ES).concatenate()\n",
    "X_train3, X_test3 = testing_model(radiomics_train, LM_train, radiomics_test, LM_test).concatenate()\n",
    "X_train4, X_test4 = testing_model(radiomics_train, LM_train_tot, radiomics_test, LM_test_tot).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, y_train = processing(X_train1, y_train)\n",
    "X_test_1, y_test = processing(X_test1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, y_train = processing(X_train2, y_train)\n",
    "X_test_2, y_test = processing(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, y_train = processing(X_train3, y_train)\n",
    "X_test_3, y_test = processing(X_test3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, y_train = processing(X_train4, y_train)\n",
    "X_test_4, y_test = processing(X_test4, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
